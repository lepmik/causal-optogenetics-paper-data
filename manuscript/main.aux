\relax 
\citation{drton2011global}
\citation{peters2017elements}
\citation{Jonas2017}
\citation{pearl2009causality}
\citation{azevedo2009equal}
\citation{daniusis2012inferring}
\citation{shimizu2006linear}
\citation{angrist2008mostly}
\citation{UpcomingMehlerPaper}
\citation{stevenson2008inferring}
\citation{honey2009predicting}
\citation{pillow2008spatio}
\citation{stevenson2008inferring}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\citation{pearl2009causality}
\citation{pinault1996novel}
\citation{lerman2017two}
\citation{nikolenko2007two}
\citation{emiliani2015all}
\citation{boyden2005millisecond}
\citation{zemelman2002selective}
\citation{pearl2009causality}
\citation{peters2017elements}
\citation{angrist2008mostly}
\citation{card1993using}
\citation{angrist2008mostly}
\citation{stevenson2008inferring}
\citation{Aravanis2007}
\@writefile{toc}{\contentsline {section}{\numberline {2}Results}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Optogenetics is not local}{5}}
\citation{pare1998impact}
\citation{destexhe1999impact}
\citation{destexhe2003high}
\citation{rudolph2006use}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Confounding as a problem for the estimation of causal effects}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces {\bf  Spatial extent of optogenetic stimulus}. Due to scattering and geometric loss the light intensity (I, cyan line) plotted as percentage of intensity exiting the optogenetic fiber follows approximately an inverse square law $ r^{-2} $ where $ r $ is the distance from the fiber. If neurons are uniformly distributed the number of affected neurons increase by $ r^{2} $ (N, black line) rendering the probability of activating a neuron approximately constant (IN, blue line). \relax }}{7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:concept}{{1}{7}}
\newlabel{fig:concept@cref}{{[figure][1][]1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Instrumental variables to resolve confounding}{8}}
\newlabel{fig:intro:1}{{(a)}{9}}
\newlabel{fig:intro:1@cref}{{[subfigure][1][2](a)}{9}}
\newlabel{sub@fig:intro:1}{{(a)}{9}}
\newlabel{sub@fig:intro:1@cref}{{[subfigure][1][2](a)}{9}}
\newlabel{fig:intro:2}{{(b)}{9}}
\newlabel{fig:intro:2@cref}{{[subfigure][2][2](b)}{9}}
\newlabel{sub@fig:intro:2}{{(b)}{9}}
\newlabel{sub@fig:intro:2@cref}{{[subfigure][2][2](b)}{9}}
\newlabel{fig:intro:3}{{(c)}{9}}
\newlabel{fig:intro:3@cref}{{[subfigure][3][2](c)}{9}}
\newlabel{sub@fig:intro:3}{{(c)}{9}}
\newlabel{sub@fig:intro:3@cref}{{[subfigure][3][2](c)}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces {\bf  A,B,C network}. A sketch of the simple network containing three neurons shows stimulation configuration with blue laser light and the connections with arrows (a). The neurons A and B are stimulated 1000 trials and the corresponding peristimulus time histogram are shown in \labelcref  {fig:intro:2} upper panel with a raster plot in the lower panel. Cross correlation histograms (CCHs) are shown in \labelcref  {fig:intro:3} where horizontal and vertical axes represents time lag in ms and counts of coincident spikes in bins of 1 ms. \relax }}{9}}
\newlabel{fig:intro}{{2}{9}}
\newlabel{fig:intro@cref}{{[figure][2][]2}{9}}
\citation{wright1921correlation}
\citation{wright1921correlation}
\citation{Sayer1990}
\citation{Mason1991}
\citation{wassermann2006all}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Larger simulated networks}{10}}
\newlabel{fig:cchvswald:0}{{(a)}{11}}
\newlabel{fig:cchvswald:0@cref}{{[subfigure][1][3](a)}{11}}
\newlabel{sub@fig:cchvswald:0}{{(a)}{11}}
\newlabel{sub@fig:cchvswald:0@cref}{{[subfigure][1][3](a)}{11}}
\newlabel{fig:cchvswald:1}{{(b)}{11}}
\newlabel{fig:cchvswald:1@cref}{{[subfigure][2][3](b)}{11}}
\newlabel{sub@fig:cchvswald:1}{{(b)}{11}}
\newlabel{sub@fig:cchvswald:1@cref}{{[subfigure][2][3](b)}{11}}
\newlabel{fig:cchvswald:2}{{(c)}{11}}
\newlabel{fig:cchvswald:2@cref}{{[subfigure][3][3](c)}{11}}
\newlabel{sub@fig:cchvswald:2}{{(c)}{11}}
\newlabel{sub@fig:cchvswald:2@cref}{{[subfigure][3][3](c)}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces {\bf  Instrumental variable estimation (IV) of connectivity}. \labelcref  {fig:cchvswald:0} In an instrumental variable estimation procedure we use a variable that is assumed to be random (here refractoriness) which influences a variable of interest (here spiking) and to use this influence to infer the causal interaction of that variable on other variables (here spiking of A or B onto C). \labelcref  {fig:cchvswald:1} A popular estimation approach for IVs, the Wald technique correctly estimates causal connectivity in the A,B,C neural network using the refractory period. Subfigure \labelcref  {fig:cchvswald:0} shows a path diagram \cite  {wright1921correlation} between the upstream neuron $ A $ or $ B $, the stimulation $ S $, the post-synaptic neuron $ C $ and the IV as $ A_{r} $ or $ B_{r} $. Arrows represent associations where $ S $ is associated with $ A,B $ and potentially also with $ C $ both directly and through $ A,B $. The IV estimator calculated by \cref  {eq:wald} converges to $ \mathaccentV {hat}05E{\beta }_{BC} \approx 0.2, \mathaccentV {hat}05E{\beta }_{AC} \approx 0 $ after approximately $ 5000 $ trials as seen in \labelcref  {fig:cchvswald:1,fig:cchvswald:2} respectively. Insets represent high resolution zoom of cross correlation histograms of BC and AC where horizontal and vertical axes represents time lag and counts of coincident spikes in bins of 0.1 ms respectively. \relax }}{11}}
\newlabel{fig:cchvswald}{{3}{11}}
\newlabel{fig:cchvswald@cref}{{[figure][3][]3}{11}}
\newlabel{fig:error:raster}{{(a)}{12}}
\newlabel{fig:error:raster@cref}{{[subfigure][1][4](a)}{12}}
\newlabel{sub@fig:error:raster}{{(a)}{12}}
\newlabel{sub@fig:error:raster@cref}{{[subfigure][1][4](a)}{12}}
\newlabel{fig:error:mse}{{(b)}{12}}
\newlabel{fig:error:mse@cref}{{[subfigure][2][4](b)}{12}}
\newlabel{sub@fig:error:mse}{{(b)}{12}}
\newlabel{sub@fig:error:mse@cref}{{[subfigure][2][4](b)}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces {\bf  Mean square error (MSE) of IV estimator in a large network}. \labelcref  {fig:error:raster} Excitatory neurons (in blue raster) are stimulated with varying intensity indicated by the y-axis in lower panel, upper panel shows inhibitory neurons (red raster) where y-axis indicate random neuron-id. \labelcref  {fig:error:mse} The IV estimator is evaluated in the asynchronous recurrent neural network at three different amounts of relative inhibition $ g $ (decreasing with model number). The MSE as a function of number of trials is shown on a logarithmic scale where the slopes was found to be $ -0.77, -0.48, -0.40 $ for model 1,2,3 respectively. \relax }}{12}}
\newlabel{fig:error}{{4}{12}}
\newlabel{fig:error@cref}{{[figure][4][]4}{12}}
\citation{pillow2008spatio}
\citation{destexhe1999impact}
\citation{rudolph2006use}
\citation{pare1998impact}
\citation{destexhe2003high}
\@writefile{toc}{\contentsline {section}{\numberline {3}Discussion}{13}}
\newlabel{fig:network-class:1}{{(a)}{14}}
\newlabel{fig:network-class:1@cref}{{[subfigure][1][5](a)}{14}}
\newlabel{sub@fig:network-class:1}{{(a)}{14}}
\newlabel{sub@fig:network-class:1@cref}{{[subfigure][1][5](a)}{14}}
\newlabel{fig:network-class:2}{{(b)}{14}}
\newlabel{fig:network-class:2@cref}{{[subfigure][2][5](b)}{14}}
\newlabel{sub@fig:network-class:2}{{(b)}{14}}
\newlabel{sub@fig:network-class:2@cref}{{[subfigure][2][5](b)}{14}}
\newlabel{fig:network-class:3}{{(c)}{14}}
\newlabel{fig:network-class:3@cref}{{[subfigure][3][5](c)}{14}}
\newlabel{sub@fig:network-class:3}{{(c)}{14}}
\newlabel{sub@fig:network-class:3@cref}{{[subfigure][3][5](c)}{14}}
\newlabel{fig:network-class:4}{{(d)}{14}}
\newlabel{fig:network-class:4@cref}{{[subfigure][4][5](d)}{14}}
\newlabel{sub@fig:network-class:4}{{(d)}{14}}
\newlabel{sub@fig:network-class:4@cref}{{[subfigure][4][5](d)}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces {\bf  False estimates and goodness of fit}. False positives are shown in \labelcref  {fig:network-class:1} for the cross correlation histogram (cch) method, logistic regression (logit) and the IV estimator (wald). False negatives for cch and wald is shown in \labelcref  {fig:network-class:2}. Positive estimates of weight as a function of true weight is scattered for the wald estimator in \labelcref  {fig:network-class:3} and cch in \labelcref  {fig:network-class:4} color coded by the size of perturbation intensity. \relax }}{14}}
\newlabel{fig:network-class}{{5}{14}}
\newlabel{fig:network-class@cref}{{[figure][5][]5}{14}}
\citation{English2017}
\citation{ermentrout2008reliability}
\citation{BenPaper}
\citation{imbens2008regression}
\citation{abadie2005semiparametric}
\citation{stuart2010matching}
\citation{king2016propensity}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Instrumental variable estimation}{16}}
\citation{wright1921correlation}
\citation{angrist2008mostly}
\newlabel{eq:regress}{{1}{17}}
\newlabel{eq:regress@cref}{{[equation][1][]1}{17}}
\citation{wald1940fitting}
\citation{cameron2005microeconometrics}
\citation{Stark2009}
\citation{English2017}
\citation{Stark2009}
\citation{English2017}
\citation{Stark2009}
\newlabel{eq:wald}{{4}{18}}
\newlabel{eq:wald@cref}{{[equation][4][]4}{18}}
\citation{English2017}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Cross correlation histogram}{19}}
\newlabel{sec:method:cch}{{4.2}{19}}
\newlabel{sec:method:cch@cref}{{[subsection][2][4]4.2}{19}}
\newlabel{eq:poissoncontcor}{{5}{19}}
\newlabel{eq:poissoncontcor@cref}{{[equation][5][]5}{19}}
\newlabel{eq:ptrans}{{6}{19}}
\newlabel{eq:ptrans@cref}{{[equation][6][]6}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Logistic regression}{19}}
\citation{Sayer1990}
\citation{Mason1991}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Simulated network}{20}}
\newlabel{eq:LIF}{{9}{20}}
\newlabel{eq:LIF@cref}{{[equation][9][]9}{20}}
\newlabel{eq:syn}{{10}{20}}
\newlabel{eq:syn@cref}{{[equation][10][]10}{20}}
\citation{Kumar2008}
\citation{Aravanis2007}
\citation{Ho2017}
\citation{Aravanis2007}
\citation{Ho2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Perturbation intensity}{21}}
\newlabel{sec:method:opto}{{4.5}{21}}
\newlabel{sec:method:opto@cref}{{[subsection][5][4]4.5}{21}}
\newlabel{eq:intensity}{{15}{21}}
\newlabel{eq:intensity@cref}{{[equation][15][]15}{21}}
\newlabel{fig:CC}{{(a)}{22}}
\newlabel{fig:CC@cref}{{[subfigure][1][6](a)}{22}}
\newlabel{sub@fig:CC}{{(a)}{22}}
\newlabel{sub@fig:CC@cref}{{[subfigure][1][6](a)}{22}}
\newlabel{fig:CV}{{(b)}{22}}
\newlabel{fig:CV@cref}{{[subfigure][2][6](b)}{22}}
\newlabel{sub@fig:CV}{{(b)}{22}}
\newlabel{sub@fig:CV@cref}{{[subfigure][2][6](b)}{22}}
\newlabel{fig:syn_dist}{{(c)}{22}}
\newlabel{fig:syn_dist@cref}{{[subfigure][3][6](c)}{22}}
\newlabel{sub@fig:syn_dist}{{(c)}{22}}
\newlabel{sub@fig:syn_dist@cref}{{[subfigure][3][6](c)}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Network state \relax }}{22}}
\newlabel{fig:state}{{6}{22}}
\newlabel{fig:state@cref}{{[figure][6][]6}{22}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Simulation parameters of three different models.\relax }}{23}}
\newlabel{tab:params}{{1}{23}}
\newlabel{tab:params@cref}{{[table][1][]1}{23}}
\bibstyle{apalike}
\bibdata{library}
\bibcite{angrist2008mostly}{Angrist and Pischke, 2008}
\bibcite{Aravanis2007}{Aravanis et\nobreakspace  {}al., 2007}
\bibcite{boyden2005millisecond}{Boyden et\nobreakspace  {}al., 2005}
\bibcite{cameron2005microeconometrics}{Cameron and Trivedi, 2005}
\bibcite{card1993using}{Card, 1993}
\bibcite{daniusis2012inferring}{Daniusis et\nobreakspace  {}al., 2012}
\bibcite{drton2011global}{Drton et\nobreakspace  {}al., 2011}
\bibcite{emiliani2015all}{Emiliani et\nobreakspace  {}al., 2015}
\bibcite{English2017}{English et\nobreakspace  {}al., 2017}
\bibcite{Ho2017}{Ho et\nobreakspace  {}al., 2017}
\bibcite{honey2009predicting}{Honey et\nobreakspace  {}al., 2009}
\bibcite{Jonas2017}{Jonas and Kording, 2017}
\bibcite{Kumar2008}{Kumar et\nobreakspace  {}al., 2008}
\bibcite{lerman2017two}{Lerman et\nobreakspace  {}al., 2017}
\bibcite{Mason1991}{Mason et\nobreakspace  {}al., 1991}
\bibcite{nikolenko2007two}{Nikolenko et\nobreakspace  {}al., 2007}
\bibcite{pare1998impact}{Par{\'e} et\nobreakspace  {}al., 1998}
\bibcite{pearl2009causality}{Pearl, 2009}
\bibcite{scikit-learn}{Pedregosa et\nobreakspace  {}al., 2011}
\bibcite{peters2017elements}{Peters et\nobreakspace  {}al., 2017}
\bibcite{pillow2008spatio}{Pillow et\nobreakspace  {}al., 2008}
\bibcite{rudolph2006use}{Rudolph and Destexhe, 2006}
\bibcite{Sayer1990}{Sayer et\nobreakspace  {}al., 1990}
\bibcite{shimizu2006linear}{Shimizu et\nobreakspace  {}al., 2006}
\bibcite{Stark2009}{Stark and Abeles, 2009}
\bibcite{stevenson2008inferring}{Stevenson et\nobreakspace  {}al., 2008a}
\bibcite{Stevenson2008}{Stevenson et\nobreakspace  {}al., 2008b}
\bibcite{wald1940fitting}{Wald, 1940}
\bibcite{wassermann2006all}{Wassermann, 2006}
\bibcite{zemelman2002selective}{Zemelman et\nobreakspace  {}al., 2002}
